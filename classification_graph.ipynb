{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font color=\"blue\"><h1> French Web Domain Classification </h1> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Done by :Saif Eddine GHRIBI & Mohamed Skander HELLAL & Ramzi Charradi </h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "import networkx as nx\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from src.preprocess import read_data, pre_process_text, filter_text\n",
    "from src.GCN import GCN,GAT,train\n",
    "from src.appnptrain import APPNPTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of files to read :\n",
    "train_data = \"data/train_noduplicates.csv\"\n",
    "test_data  = \"data/test.csv\"\n",
    "texts_path = \"data/text/text\"\n",
    "\n",
    "# save files to :\n",
    "train_preprocessed = \"saved_files/train_graph.csv\"\n",
    "test_preprocessed = \"saved_files/test_graph.csv\"\n",
    "\n",
    "# preprocessing :\n",
    "num_words = 2000\n",
    "do_stem = False\n",
    "do_tokenize = False\n",
    "\n",
    "# text filters\n",
    "min_word_length = 4\n",
    "min_text_length = 20\n",
    "\n",
    "# k_core decomposition\n",
    "do_kcore = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "import time\n",
    "start = time.time()\n",
    "df, test_df = read_data(train_data, test_data, texts_path)\n",
    "end = time.time()\n",
    "# drop empty rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "tqdm.pandas()\n",
    "print(\"Preprocessing training data...\")\n",
    "df[\"text\"] = df[\"text\"].progress_apply( lambda x : pre_process_text(x, num_words, do_stem, do_tokenize))\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df[\"text\"] = test_df[\"text\"].progress_apply( lambda x : pre_process_text(x, num_words, do_stem, do_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering data\n",
    "tqdm.pandas()\n",
    "print(\"Filtering training data...\")\n",
    "df[\"text\"] = df[\"text\"].progress_apply( lambda x : filter_text(x, min_word_length = 4 , min_text_length = 15,dataset = \"train\"))\n",
    "df = df[df.text!=\"No text\"]\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Filtering test data...\")\n",
    "test_df[\"text\"] = test_df[\"text\"].progress_apply( lambda x : filter_text(x, min_word_length = 4 , min_text_length = 0,dataset =\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed, weighted graph\n",
    "graph = nx.read_weighted_edgelist('data/edgelist.txt',create_using=nx.DiGraph())    \n",
    "graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = df.node.values.tolist()\n",
    "train_nodes = [str(node) for node in train_nodes]\n",
    "nodelist = list(df.node.apply(lambda x : str(x)).values)\n",
    "graph = graph.subgraph(train_nodes)\n",
    "adj = nx.adjacency_matrix(graph,nodelist)\n",
    "adj = torch.FloatTensor(np.array(adj.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(decode_error='ignore', strip_accents='unicode', encoding='latin-1'\n",
    "                       , min_df=10, max_df=1000,max_features = 3000)\n",
    "features = vec.fit_transform(df.text)\n",
    "features = torch.FloatTensor(features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.label\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if use_gpu:\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 20\n",
    "model, optimizer = None, None\n",
    "\n",
    "model = GCN(\n",
    "            nfeat = features.shape[1],\n",
    "            nhid = 64,\n",
    "            nclass = 8,\n",
    "            dropout = 0.5,\n",
    "            init = 'xavier'\n",
    "    )\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr = 5e-3,\n",
    "            weight_decay = 5e-4,\n",
    "            momentum = 0.9\n",
    "    )\n",
    "model.cuda()\n",
    "features = features.cuda()\n",
    "adj = adj.cuda()\n",
    "labels = labels.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs) : \n",
    "    train(model,optimizer,features,adj,labels,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Attention Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = None, None\n",
    "\n",
    "model = GAT(\n",
    "            nfeat = features.shape[1],\n",
    "            nhid = 64,\n",
    "            nclass = 8,\n",
    "            dropout = 0.5,\n",
    "            alpha = 0.2,\n",
    "            nheads = 8\n",
    "    )\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr = 5e-3,\n",
    "            weight_decay = 5e-4,\n",
    "            momentum = 0.9\n",
    "    )\n",
    "\n",
    "model.cuda()\n",
    "features = features.cuda()\n",
    "adj = adj.cuda()\n",
    "labels = labels.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs) : \n",
    "    train(model,optimizer,features,adj,labels,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "model = \"exact\"\n",
    "epochs =2000\n",
    "seed = 42\n",
    "iterations = 10\n",
    "early_stopping_rounds = 1000\n",
    "train_size = 1500\n",
    "dropout = 0.5\n",
    "alpha  =0.1\n",
    "learning_rate =0.01\n",
    "lambd = 0.005\n",
    "layers = [64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features dictionnary\n",
    "feature_dict = dict()\n",
    "for i in range(adj.shape[0]):\n",
    "    l =  features[i].tolist()\n",
    "    feature_dict[df.node[i]] = [ j for j in range(len(l)) if l[j]!=0]\n",
    "# Target\n",
    "target = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appnp = APPNPTrainer(graph,feature,target,model,layers,dropout,iterations,alpha\n",
    "                    ,train_size,lambd,learning_rate,epochs,early_stopping_rounds)\n",
    "appnp.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
